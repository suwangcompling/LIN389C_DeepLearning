{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning 03. Recurrent Neural Nets (RNN)\n",
    "\n",
    "* **Implementation 4a**: RNN with Keras (basics)\n",
    "    * *Source*: My RNN code at https://github.com/suwangcompling/texasdataday2017/blob/master/NER_ATIS.ipynb\n",
    "    * *Contribution*: \n",
    "        * Hopefully clearer pipeline\n",
    "\n",
    "* **Implementation 4b**: RNN with Keras (bidirectional setup + tuning options)\n",
    "    * *Advanced Model*: Bi-LSTM-CRF (https://github.com/glample/tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Implementation 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, os, random\n",
    "os.environ['KERAS_BACKEND']='tensorflow' \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Activation, TimeDistributed\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "path = \"/Users/jacobsw/Desktop/WORK/OJO/NER_PRESENTATION/DATA/atis.pkl\"\n",
    "train_triple, valid_triple, test_triple, dicts = pickle.load(open(path, 'rb'))\n",
    "\n",
    "X_train, Y_train = train_triple[0], train_triple[2]\n",
    "X_valid, Y_valid = valid_triple[0], valid_triple[2]\n",
    "X_test, Y_test = test_triple[0], test_triple[2]\n",
    "\n",
    "l2i = dicts['labels2idx']\n",
    "w2i = dicts['words2idx']\n",
    "i2l = {i:l for l,i in l2i.iteritems()}\n",
    "i2w = {i:w for w,i in w2i.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET CONFIGS\n",
    "\n",
    "vocab_size = len(w2i)\n",
    "label_size = len(l2i)\n",
    "emb_size = 100\n",
    "hidden_size = 100\n",
    "\n",
    "num_epochs = 20\n",
    "valid_freq = 1000\n",
    "valid_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dim_transform_x(x):\n",
    "    \"\"\"\n",
    "    Reshape an x data point to [batch_size, length].\n",
    "    \n",
    "    Arguments:\n",
    "    x: Single x data point.\n",
    "    \n",
    "    Returns reshaped data point.\n",
    "    \"\"\"\n",
    "    return np.asarray([x])\n",
    "\n",
    "def dim_transform_y(y):\n",
    "    \"\"\"\n",
    "    Reshape an y data point to [batch_size, length, label_size] (in binarized representation).\n",
    "    \n",
    "    Arguments:\n",
    "    y: Single y data point.\n",
    "    \n",
    "    Returns reshaped data point.\n",
    "    \"\"\"\n",
    "    return to_categorical(np.asarray(y)[:,np.newaxis], nb_classes=label_size)[np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINSFORM DATA TO FIT INPUT REQUIREMENTS\n",
    "\n",
    "X_train, X_valid, X_test = map(dim_transform_x, X_train), map(dim_transform_x, X_valid), map(dim_transform_x, X_test)\n",
    "Y_train, Y_valid, Y_test = map(dim_transform_y, Y_train), map(dim_transform_y, Y_valid), map(dim_transform_y, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_8 (Embedding)          (None, None, 100)     57200       embedding_input_8[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, None, 100)     80400       embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_6 (TimeDistribut (None, None, 127)     12827       lstm_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, None, 127)     0           timedistributed_6[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 150427\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILD COMPUTATIONAL GRAPH\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(Embedding(input_dim=vocab_size, output_dim=emb_size))\n",
    "rnn.add(LSTM(output_dim=hidden_size, activation='relu', return_sequences=True))\n",
    "rnn.add(TimeDistributed(Dense(output_dim=label_size)))\n",
    "rnn.add(Activation('softmax'))\n",
    "rnn.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Cost/Accuracy at Iteration 1000 : 0.630596980916 0.860808443064\n",
      "Validation Cost/Accuracy at Iteration 2000 : 0.404342949591 0.911917387688\n",
      "Validation Cost/Accuracy at Iteration 3000 : 0.319398777756 0.9242008791\n",
      "Validation Cost/Accuracy at Iteration 4000 : 0.241086330384 0.939273726382\n",
      "Validation Cost/Accuracy at Iteration 5000 : 0.193205771447 0.957866637992\n",
      "Validation Cost/Accuracy at Iteration 6000 : 0.120419648209 0.971302836597\n",
      "Validation Cost/Accuracy at Iteration 7000 : 0.143774769793 0.966408751208\n",
      "Validation Cost/Accuracy at Iteration 8000 : 0.0945306488611 0.976764610591\n",
      "Validation Cost/Accuracy at Iteration 9000 : 0.0704847894763 0.980819010238\n",
      "Validation Cost/Accuracy at Iteration 10000 : 0.0993882891076 0.980816777993\n",
      "Validation Cost/Accuracy at Iteration 11000 : 0.070867968236 0.980805333555\n",
      "Validation Cost/Accuracy at Iteration 12000 : 0.0725929829256 0.980705998394\n",
      "Validation Cost/Accuracy at Iteration 13000 : 0.0701369878041 0.978846239016\n",
      "Validation Cost/Accuracy at Iteration 14000 : 0.055321096814 0.985591687123\n",
      "Validation Cost/Accuracy at Iteration 15000 : 0.082208160485 0.98152576182\n",
      "Validation Cost/Accuracy at Iteration 16000 : 0.0932055813751 0.979833971584\n",
      "Validation Cost/Accuracy at Iteration 17000 : 0.097235277678 0.98339066227\n",
      "Validation Cost/Accuracy at Iteration 18000 : 0.0744492412313 0.979834560048\n",
      "Validation Cost/Accuracy at Iteration 19000 : 0.149206025631 0.96492680565\n",
      "Validation Cost/Accuracy at Iteration 20000 : 0.0972592044409 0.986194611976\n",
      "Validation Cost/Accuracy at Iteration 21000 : 0.0991858438673 0.982092270689\n",
      "Validation Cost/Accuracy at Iteration 22000 : 0.0983152137044 0.98189093831\n",
      "Validation Cost/Accuracy at Iteration 23000 : 0.0776311035459 0.981572089947\n",
      "Validation Cost/Accuracy at Iteration 24000 : 0.0822273398102 0.991286680912\n",
      "Validation Cost/Accuracy at Iteration 25000 : 0.0475360258085 0.981868856144\n",
      "Validation Cost/Accuracy at Iteration 26000 : 0.0620118604078 0.984955646692\n",
      "Validation Cost/Accuracy at Iteration 27000 : 0.0941353762938 0.981714716656\n",
      "Validation Cost/Accuracy at Iteration 28000 : 0.0432620983387 0.989858604845\n",
      "Validation Cost/Accuracy at Iteration 29000 : 0.134825625153 0.975181401931\n",
      "Validation Cost/Accuracy at Iteration 30000 : 0.0676169956768 0.985461650922\n",
      "Validation Cost/Accuracy at Iteration 31000 : 0.0941777639801 0.979448412698\n",
      "Validation Cost/Accuracy at Iteration 32000 : 0.0983376825217 0.982498677249\n",
      "Validation Cost/Accuracy at Iteration 33000 : 0.0787985636896 0.985039990647\n",
      "Validation Cost/Accuracy at Iteration 34000 : 0.119217622772 0.97979540884\n",
      "Validation Cost/Accuracy at Iteration 35000 : 0.0867029541723 0.985737429237\n",
      "Validation Cost/Accuracy at Iteration 36000 : 0.134242145902 0.979425007182\n",
      "Validation Cost/Accuracy at Iteration 37000 : 0.200994423362 0.969505622452\n",
      "Validation Cost/Accuracy at Iteration 38000 : 0.0723596818541 0.986741180603\n",
      "Validation Cost/Accuracy at Iteration 39000 : 0.0683249885629 0.98984563785\n",
      "Validation Cost/Accuracy at Iteration 40000 : 0.131889400835 0.982657325131\n",
      "Validation Cost/Accuracy at Iteration 41000 : 0.095033911442 0.982094445552\n",
      "Validation Cost/Accuracy at Iteration 42000 : 0.0930074410239 0.98365492958\n",
      "Validation Cost/Accuracy at Iteration 43000 : 0.0718948281366 0.987338141026\n",
      "Validation Cost/Accuracy at Iteration 44000 : 0.082216739769 0.983591117216\n",
      "Validation Cost/Accuracy at Iteration 45000 : 0.119315527093 0.975061091686\n",
      "Validation Cost/Accuracy at Iteration 46000 : 0.128825071965 0.980573260073\n",
      "Validation Cost/Accuracy at Iteration 47000 : 0.0433949017442 0.992088402825\n",
      "Validation Cost/Accuracy at Iteration 48000 : 0.101449182128 0.984457912458\n",
      "Validation Cost/Accuracy at Iteration 49000 : 0.131200355529 0.981513986014\n",
      "Validation Cost/Accuracy at Iteration 50000 : 0.115522700698 0.977839225991\n",
      "Validation Cost/Accuracy at Iteration 51000 : 0.0767026057963 0.985096350509\n",
      "Validation Cost/Accuracy at Iteration 52000 : 0.116610531507 0.98183022533\n",
      "Validation Cost/Accuracy at Iteration 53000 : 0.0419980216608 0.987815161891\n",
      "Validation Cost/Accuracy at Iteration 54000 : 0.134853158726 0.981954885392\n",
      "Validation Cost/Accuracy at Iteration 55000 : 0.0696760871645 0.988216123359\n",
      "Validation Cost/Accuracy at Iteration 56000 : 0.0920862521988 0.983744053762\n",
      "Validation Cost/Accuracy at Iteration 57000 : 0.100844216167 0.98654516317\n",
      "Validation Cost/Accuracy at Iteration 58000 : 0.0599914464432 0.992055860806\n",
      "Validation Cost/Accuracy at Iteration 59000 : 0.198353185089 0.976215966051\n",
      "Validation Cost/Accuracy at Iteration 60000 : 0.0949643262541 0.987106120932\n",
      "Validation Cost/Accuracy at Iteration 61000 : 0.0951792011279 0.982720013646\n",
      "Validation Cost/Accuracy at Iteration 62000 : 0.0933282926692 0.98275528638\n",
      "Validation Cost/Accuracy at Iteration 63000 : 0.199296649828 0.975680037555\n",
      "Validation Cost/Accuracy at Iteration 64000 : 0.0901573026669 0.983120879121\n",
      "Validation Cost/Accuracy at Iteration 65000 : 0.112411752882 0.977377996867\n",
      "Validation Cost/Accuracy at Iteration 66000 : 0.126352889169 0.985147839519\n",
      "Validation Cost/Accuracy at Iteration 67000 : 0.107661231815 0.984577043871\n",
      "Validation Cost/Accuracy at Iteration 68000 : 0.199220192579 0.973582958708\n",
      "Validation Cost/Accuracy at Iteration 69000 : 0.0476702494758 0.992804511278\n",
      "Validation Cost/Accuracy at Iteration 70000 : 0.092819010879 0.986762192056\n",
      "Validation Cost/Accuracy at Iteration 71000 : 0.109916900798 0.973445250828\n",
      "Validation Cost/Accuracy at Iteration 72000 : 0.0727542731327 0.985527912591\n",
      "Validation Cost/Accuracy at Iteration 73000 : 0.215869725749 0.97889209973\n",
      "Validation Cost/Accuracy at Iteration 74000 : 0.115757844987 0.982387756035\n",
      "Validation Cost/Accuracy at Iteration 75000 : 0.122396487441 0.97976747558\n",
      "Validation Cost/Accuracy at Iteration 76000 : 0.101020101777 0.983943320568\n",
      "Validation Cost/Accuracy at Iteration 77000 : 0.118113378931 0.981601037851\n",
      "Validation Cost/Accuracy at Iteration 78000 : 0.106839086169 0.98543582398\n",
      "Validation Cost/Accuracy at Iteration 79000 : 0.0892001500839 0.98744447192\n",
      "Test Cost/Accuracy: 0.285456630415 0.96842926734\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "num_iters = 0\n",
    "\n",
    "for i in xrange(num_epochs):\n",
    "    for t in xrange(len(X_train)):\n",
    "        rnn.train_on_batch(X_train[t], Y_train[t])\n",
    "        num_iters += 1\n",
    "        if num_iters%valid_freq==0:\n",
    "            valid_ids = random.sample(range(len(X_valid)), valid_size)\n",
    "            valid_costs, valid_accs = [], []\n",
    "            for v in valid_ids:\n",
    "                valid_cost, valid_acc = rnn.evaluate(X_valid[v], Y_valid[v], verbose=0)\n",
    "                valid_costs.append(valid_cost); valid_accs.append(valid_acc)\n",
    "            print \"Validation Cost/Accuracy at Iteration\", num_iters, \":\", np.mean(valid_costs), np.mean(valid_accs) \n",
    "\n",
    "# EVALUATE    \n",
    "\n",
    "test_costs, test_accs = [], []\n",
    "for e in xrange(len(X_test)):\n",
    "    test_cost, test_acc = rnn.evaluate(X_test[e], Y_test[e], verbose=0)\n",
    "    test_costs.append(test_cost); test_accs.append(test_acc)\n",
    "print \"Test Cost/Accuracy:\", np.mean(test_costs), np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Implementation 4b\n",
    "\n",
    "* Tuning:\n",
    "    * Regularization: Dropout\n",
    "    * Learning: Learning Decay\n",
    "\n",
    "**NB**: Load data using code in Impl. 4a first. \n",
    "\n",
    "**NB**: Providing syntax. Tuning needed to make this thing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(w2i)\n",
    "label_size = len(l2i)\n",
    "emb_size = 100\n",
    "hidden_size = 100\n",
    "\n",
    "num_epochs = 20\n",
    "valid_freq = 1000\n",
    "valid_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_12 (Embedding)         (None, None, 100)     57200       embedding_input_12[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional)  (None, None, 200)     160800      embedding_12[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, None, 200)     0           bidirectional_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional)  (None, None, 200)     240800      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, None, 200)     0           bidirectional_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_10 (TimeDistribu (None, None, 127)     25527       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, None, 127)     0           timedistributed_10[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 484327\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILD COMPUTATIONAL GRAPH\n",
    "\n",
    "bilstm = Sequential()\n",
    "bilstm.add(Embedding(input_dim=vocab_size, output_dim=emb_size))\n",
    "bilstm.add(Bidirectional(LSTM(output_dim=hidden_size, activation='relu', return_sequences=True)))\n",
    "bilstm.add(Dropout(p=0.5))\n",
    "bilstm.add(Bidirectional(LSTM(output_dim=hidden_size, activation='relu', return_sequences=True)))\n",
    "bilstm.add(Dropout(p=0.5))\n",
    "bilstm.add(TimeDistributed(Dense(output_dim=label_size)))\n",
    "bilstm.add(Activation('softmax'))\n",
    "\n",
    "adam = Adam(decay=0.9)\n",
    "bilstm.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "num_iters = 0\n",
    "\n",
    "for i in xrange(num_epochs):\n",
    "    for t in xrange(len(X_train)):\n",
    "        bilstm.train_on_batch(X_train[t], Y_train[t])\n",
    "        num_iters += 1\n",
    "        if num_iters%valid_freq==0:\n",
    "            valid_ids = random.sample(range(len(X_valid)), valid_size)\n",
    "            valid_costs, valid_accs = [], []\n",
    "            for v in valid_ids:\n",
    "                valid_cost, valid_acc = bilstm.evaluate(X_valid[v], Y_valid[v], verbose=0)\n",
    "                valid_costs.append(valid_cost); valid_accs.append(valid_acc)\n",
    "            print \"Validation Cost/Accuracy at Iteration\", num_iters, \":\", np.mean(valid_costs), np.mean(valid_accs)\n",
    "    \n",
    "# EVALUATE    \n",
    "\n",
    "test_costs, test_accs = [], []\n",
    "for e in xrange(len(X_test)):\n",
    "    test_cost, test_acc = bilstm.evaluate(X_test[e], Y_test[e], verbose=0)\n",
    "    test_costs.append(test_cost); test_accs.append(test_acc)\n",
    "print \"Test Cost/Accuracy:\", np.mean(test_costs), np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
